#version 450
#extension GL_GOOGLE_include_directive : enable

#include "../hostDeviceShared.h"

layout (local_size_x = 16, local_size_y = 16) in;

struct ViewProjMat
{
	mat4 view;
	mat4 proj;
};

layout(binding = 0) uniform CameraProperties 
{
	VIEWPROJ_BLOCK
} cam;
layout (binding = 1, rgba32f) uniform readonly image2D inNoisyImage;
layout (binding = 2, rgba32f) uniform readonly image2D inNoraml;
layout (binding = 3, rgba32f) uniform readonly image2D inDiffuseCol;
layout (binding = 4, rgba32f) uniform readonly image2D inDepth;
layout (binding = 5, rgba32f) uniform image2DArray accumImage;
layout (binding = 6, r32f) uniform image2DArray depthAccumImage;
layout (binding = 7) buffer ViewProjMatrices { ViewProjMat mat[]; } viewProjMatrices;
layout (binding = 8, rgba32f) uniform image2D outFilteredImage;

layout (push_constant) uniform pcBlock {
	uint frameIndex;
	uint windowSize;
	uint reset;
} pcb;

/*
vec3 computeWeightedOutput(in ivec2 pixel)
{
	vec3 newNormal = imageLoad(inNoraml, pixel).rgb;
	vec3 newColor = imageLoad(inDiffuseCol, pixel).rgb;
	float newGreyColor = (newColor.x + newColor.y + newColor.z) / 3.0 * (newNormal.z > 0 ? 1.0 : -1.0);
	float newDepth =  imageLoad(inDepth, pixel).r;
	imageStore(depthAccumImage, ivec3(pixel, pcb.frameIndex % pcb.windowSize), vec4(newDepth));

	uint midIndex = (pcb.frameIndex + (pcb.windowSize >> 1) + 1) % pcb.windowSize;
	vec4 reference = imageLoad(auxImage, ivec3(pixel, midIndex)).rgba;
	vec3 refN = vec3(reference.xy, sqrt(1 - reference.x*reference.x - reference.y*reference.y) * (reference.z > 0 ? 1.0 : -1.0));
	float refC = reference.z > 0 ? reference.z : -reference.z;

	vec3 color = vec3(0);
	float normalization;
	for (uint i = 0; i < pcb.windowSize; i++)
	{
		uint index  = (pcb.frameIndex + i + 1) % pcb.windowSize;
		vec3 col = imageLoad(accumImage, ivec3(pixel, index)).rgb;
		
		if (index == midIndex) {
			color += col;
			normalization += 1;
		}
		else {
			vec4 current = imageLoad(auxImage, ivec3(pixel, index)).rgba;
			vec3 currentN = vec3(current.xy, sqrt(1 - current.x*current.x - current.y*current.y) * (current.z > 0 ? 1.0 : -1.0));
			float currentC = current.z > 0 ? current.z : -current.z;

			float weight = dot(currentN, refN) * (abs(currentC - refC) > 0.01 ? 0 : 1);
			weight = (weight > 0 ? weight : 0);
			color += col * weight;
			normalization += weight;
		}
	}

	return color / normalization;
}
*/
ivec2 findPixelPosition(in vec4 wPos, in ivec2 screenExtent, in uint windowFrameIdx)
{
	ViewProjMat vpMat = viewProjMatrices.mat[windowFrameIdx];
	vec4 ndcSpace = vpMat.proj * (vpMat.view * wPos);
	ndcSpace /= ndcSpace.w;
	ndcSpace.xy = ndcSpace.xy * 0.5 + 0.5;
	
	if (ndcSpace.x < 0.0001 || ndcSpace.x > 0.9999 || ndcSpace.y < 0.0001 || ndcSpace.y > 0.9999)
		return ivec2(-1, -1);

	return ivec2(ndcSpace.xy * screenExtent);
}

vec3 computeCameraMotionFix(in vec4 wPos, in ivec2 screenExtent, in uint midIndex, in float refDepth, in ivec2 currentPixel)
{
	vec3 color = vec3(0);
	float normalization = 0;
	float weight = 0;
	float depth = 0;
	ivec2 pixel;
	for (uint i = 0; i < pcb.windowSize; i++) {
		uint index  = i; //(pcb.frameIndex + i + 1) % pcb.windowSize;

		if (i == midIndex)
			pixel = currentPixel;
		else
			pixel = findPixelPosition(wPos, screenExtent, i);

		if (pixel.x >= 0) {
			depth = imageLoad(depthAccumImage, ivec3(pixel, index)).r;
			weight = abs(depth - refDepth) > 0.001 * refDepth ? 0 : 1;
			color += imageLoad(accumImage, ivec3(pixel, index)).rgb * weight;
			normalization += weight;
		}
	}

	return color / normalization;
}

void main()
{	
	ivec2 screenExtent = imageSize(inNoisyImage);
	ivec2 pixel = ivec2(gl_GlobalInvocationID.x, gl_GlobalInvocationID.y);
	
	if (pixel.x >= screenExtent.x || pixel.y >= screenExtent.y)
		return;
	
	ViewProjMat vpMat;

	if ((pcb.reset & 1) == 1) {
		vpMat.view = vpMat.proj = mat4(1.0);
		for (uint i = 0; i < pcb.windowSize; i++) {
			imageStore(accumImage, ivec3(pixel, i), vec4(0));
			imageStore(depthAccumImage, ivec3(pixel, i), vec4(0));
			viewProjMatrices.mat[i] = vpMat;
		}
		imageStore(outFilteredImage, pixel, vec4(0));
	}

	// Store into window buffers
	vec4 new = imageLoad(inNoisyImage, pixel).rgba;
	imageStore(accumImage, ivec3(pixel, pcb.frameIndex % pcb.windowSize), new);
	float depth =  imageLoad(inDepth, pixel).r;
	imageStore(depthAccumImage, ivec3(pixel, pcb.frameIndex % pcb.windowSize), vec4(depth));
	vpMat.view = cam.view;
	vpMat.proj = cam.proj;
	viewProjMatrices.mat[pcb.frameIndex % pcb.windowSize] = vpMat;

	// compute world position of mid window frame
	uint midIndex = (pcb.frameIndex + (pcb.windowSize >> 1) + 1) % pcb.windowSize;
	vpMat = viewProjMatrices.mat[midIndex];
	vpMat.view = inverse(vpMat.view);
	vpMat.proj = inverse(vpMat.proj);
	depth = imageLoad(depthAccumImage, ivec3(pixel, midIndex)).r;
	const vec2 pixelCenter = vec2(pixel) + vec2(0.5);
	const vec2 inUV = pixelCenter/vec2(screenExtent);
	vec2 d = inUV * 2.0 - 1.0;
	vec4 cameraPosition = vpMat.view * vec4(0,0,0,1);
	vec4 target = vpMat.proj * vec4(d.x, d.y, 1, 1) ;
	vec4 viewDir = vpMat.view * vec4(normalize(target.xyz), 0) ;
	vec4 wPos = cameraPosition + depth * viewDir;
	wPos.w = 1.0;
	
	vec4 color;
	if (((pcb.reset >> 8) & 0xff) == 0) {
		vec4 old = imageLoad(accumImage, ivec3(pixel, (pcb.frameIndex + 1) % pcb.windowSize));
		color = imageLoad(outFilteredImage, pixel).rgba + (new - old) / pcb.windowSize;
	}
	else 
		color = vec4(computeCameraMotionFix(wPos, screenExtent, midIndex, depth, pixel), 1);

	// test findPixelPosition
	//color = vec4(abs(vec2(pixel - findPixelPosition(wPos, screenExtent, pcb.frameIndex % pcb.windowSize))), 0, 1);
	imageStore(outFilteredImage, pixel, color);
}